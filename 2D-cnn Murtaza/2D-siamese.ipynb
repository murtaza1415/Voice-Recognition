{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from scipy import signal\n",
    "from sklearn.svm import SVC\n",
    "from IPython import display\n",
    "from IPython.display import SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "#from keras.utils import model_to_dot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Conv2D, Dropout, MaxPooling2D, AveragePooling2D, Flatten, Dense, Activation, BatchNormalization, Lambda\n",
    "from python_speech_features import mfcc\n",
    "\n",
    "#For fft spectrum.\n",
    "import sigproc\n",
    "import constants as c\n",
    "from scipy.signal import lfilter, butter\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "#import psutil\n",
    "#p = psutil.Process()\n",
    "#p.cpu_affinity([0,1,2,5,9,13,17,18,19,20,23,27,28,29,30,31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for fft spectrum. Copied from 'https://github.com/linhdvu14/vggvox-speaker-identification/blob/master'\n",
    "def remove_dc_and_dither(sin, sample_rate):\n",
    "\tif sample_rate == 16e3:\n",
    "\t\talpha = 0.99\n",
    "\telif sample_rate == 8e3:\n",
    "\t\talpha = 0.999\n",
    "\telse:\n",
    "\t\tprint(\"Sample rate must be 16kHz or 8kHz only\")\n",
    "\t\texit(1)\n",
    "\tsin = lfilter([1,-1], [1,-alpha], sin)\n",
    "\tdither = np.random.random_sample(len(sin)) + np.random.random_sample(len(sin)) - 1\n",
    "\tspow = np.std(dither)\n",
    "\tsout = sin + 1e-6 * spow * dither\n",
    "\treturn sout\n",
    "        \n",
    "\n",
    "def normalize_frames(m,epsilon=1e-12):\n",
    "\treturn np.array([(v - np.mean(v)) / max(np.std(v),epsilon) for v in m])\n",
    "\n",
    "\n",
    "def get_fft_spectrum(signal, buckets=None):\n",
    "\t#signal = load_wav(filename,c.SAMPLE_RATE)\n",
    "\tsignal *= 2**15\n",
    "\n",
    "\t# get FFT spectrum\n",
    "\tsignal = remove_dc_and_dither(signal, c.SAMPLE_RATE)\n",
    "\t#signal = sigproc.preemphasis(signal, coeff=c.PREEMPHASIS_ALPHA)\n",
    "\tframes = sigproc.framesig(signal, frame_len=c.FRAME_LEN*c.SAMPLE_RATE, frame_step=c.FRAME_STEP*c.SAMPLE_RATE, winfunc=np.hamming)\n",
    "\tfft = abs(np.fft.fft(frames,n=c.NUM_FFT))\n",
    "\tfft_norm = normalize_frames(fft.T)\n",
    "\n",
    "\t# truncate to max bucket sizes\n",
    "\t#rsize = max(k for k in buckets if k <= fft_norm.shape[1])\n",
    "\t#rstart = int((fft_norm.shape[1]-rsize)/2)\n",
    "\t#out = fft_norm[:,rstart:rstart+rsize]\n",
    "\n",
    "\t#return out\n",
    "\treturn fft_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network():\n",
    "    model_input = Input(shape=(512,299,1))\n",
    "    \n",
    "    conv1 = Conv2D(filters=96, kernel_size=(7, 7), strides=(2, 2))(model_input)\n",
    "    conv1 = BatchNormalization(scale=False, axis=3)(conv1)\n",
    "    conv1 = Activation('relu')(conv1) \n",
    "    mpool1 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=256, kernel_size=(5, 5), strides=(2, 2))(mpool1)\n",
    "    conv2 = BatchNormalization(scale=False, axis=3)(conv2)\n",
    "    conv2 = Activation('relu')(conv2) \n",
    "    mpool2 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1))(mpool2)\n",
    "    conv3 = BatchNormalization(scale=False, axis=3)(conv3)\n",
    "    conv3 = Activation('relu')(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))(conv3)\n",
    "    conv4 = BatchNormalization(scale=False, axis=3)(conv4)\n",
    "    conv4 = Activation('relu')(conv4) \n",
    "    \n",
    "    conv5 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))(conv4)\n",
    "    conv5 = BatchNormalization(scale=False, axis=3)(conv5)\n",
    "    conv5 = Activation('relu')(conv5)\n",
    "    conv5 = Dropout(0.25)(conv5)\n",
    "    mpool5 = MaxPooling2D(pool_size=(3, 3), strides=(2,2))(conv5)\n",
    "    \n",
    "    fc6 = Conv2D(filters=4096, kernel_size=(11, 1), strides=(1, 1))(mpool5)\n",
    "    fc6 = BatchNormalization(scale=False, axis=3)(fc6)\n",
    "    fc6 = Activation('relu')(fc6) \n",
    "    fc6 = Dropout(0.35)(fc6)\n",
    "    apool6 = AveragePooling2D(pool_size=(1, 5), strides=(1,1))(fc6)\n",
    "    \n",
    "    flatten = Flatten()(apool6)\n",
    "    \n",
    "    fc7 = Dense(1024, activation='relu')(flatten)\n",
    "    fc7 = Dropout(0.35)(fc7)\n",
    "    \n",
    "    fc8 = Dense(1024, activation='softmax')(fc7)\n",
    "    #fc8 = Dense(1211, activation='softmax', name='classifcation')(fc7)\n",
    "    \n",
    "    feature_model = Model(model_input, fc7)\n",
    "    \n",
    "    return feature_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_siamese_network():\n",
    "    base_network = create_base_network()\n",
    "    ##########################################\n",
    "    #           Load weights here.          #\n",
    "    ##########################################\n",
    "    \n",
    "    base_network.load_weights('/data/techresearch/Murtaza/vox2/dev/weights4/weights_4_26.h5', by_name=True)\n",
    "    \n",
    "    input_a = Input(shape=(512,299,1))\n",
    "    input_b = Input(shape=(512,299,1))\n",
    "    \n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "    \n",
    "    distance = Lambda(euclidean_distance,\n",
    "                      output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "    \n",
    "    out = Dense(1, activation='sigmoid')(distance)\n",
    "    \n",
    "    siamese = Model([input_a, input_b], out)\n",
    "    return siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/techresearch/anaconda2/envs/bob3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/techresearch/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 512, 299, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 512, 299, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 1024)         18729440    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            2           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 18,729,442\n",
      "Trainable params: 18,718,754\n",
      "Non-trainable params: 10,688\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese = create_siamese_network()\n",
    "siamese.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_audios = glob(\"/data/techresearch/Murtaza/vox2/dev/wav/*/*.wav\")\n",
    "#random.shuffle(all_audios)\n",
    "audio_rate = 16000\n",
    "no_seconds = 3\n",
    "\n",
    "speakers = glob(\"/data/techresearch/Murtaza/vox2/dev/wav/*\")\n",
    "random.shuffle(speakers)\n",
    "    \n",
    "def create_batch():\n",
    "    labels = []\n",
    "    input_A = []\n",
    "    input_B = []\n",
    "    \n",
    "    global speakers\n",
    "    current_speaker = random.choice(speakers)\n",
    "    current_speaker_audios = glob(current_speaker + '/*.wav')\n",
    "    \n",
    "    \n",
    "    \n",
    "    label = 0\n",
    "    labels.append(label)   \n",
    "    while True:\n",
    "        audio_A1 = random.choice(current_speaker_audios)\n",
    "        audio_data, _ = librosa.load(sr=None, mono=True, path=audio_A1)\n",
    "        if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                    start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                    end = start + (audio_rate*no_seconds)\n",
    "                    audio_clip = audio_data[start : end]\n",
    "                    image = audio_to_image(audio_clip, audio_rate)\n",
    "                    audio_A1_image = np.reshape(image, (512,299,1))\n",
    "                    input_A.append(audio_A1_image)\n",
    "                    break\n",
    "    while True:\n",
    "        audio_B1 = random.choice(current_speaker_audios)\n",
    "        audio_data, _ = librosa.load(sr=None, mono=True, path=audio_B1)\n",
    "        if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                    start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                    end = start + (audio_rate*no_seconds)\n",
    "                    audio_clip = audio_data[start : end]\n",
    "                    image = audio_to_image(audio_clip, audio_rate)\n",
    "                    audio_B1_image = np.reshape(image, (512,299,1))\n",
    "                    input_B.append(audio_B1_image)\n",
    "                    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        random_speaker = random.choice(speakers)\n",
    "        if random_speaker != current_speaker:         #The loop will run again if random.choice() resulted in the same speaker. Different is required.\n",
    "            break   \n",
    "    random_speaker_audios = glob(random_speaker + '/*.wav')\n",
    "    label = 1\n",
    "    labels.append(label)\n",
    "    audio_B2 = random.choice(random_speaker_audios)\n",
    "    audio_data, _ = librosa.load(sr=None, mono=True, path=audio_B2)\n",
    "    if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                end = start + (audio_rate*no_seconds)\n",
    "                audio_clip = audio_data[start : end]\n",
    "                image = audio_to_image(audio_clip, audio_rate)\n",
    "                audio_B2_image = np.reshape(image, (512,299,1))\n",
    "                input_B.append(audio_B2_image)\n",
    "                break\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        random_speaker = random.choice(speakers)\n",
    "        if random_speaker != current_speaker:         #The loop will run again if random.choice() resulted in the same speaker. Different is required.\n",
    "            break   \n",
    "    random_speaker_audios = glob(random_speaker + '/*.wav')\n",
    "    label = 1\n",
    "    labels.append(label)\n",
    "    audio_B3 = random.choice(random_speaker_audios)\n",
    "    audio_data, _ = librosa.load(sr=None, mono=True, path=audio_B3)\n",
    "    if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                end = start + (audio_rate*no_seconds)\n",
    "                audio_clip = audio_data[start : end]\n",
    "                image = audio_to_image(audio_clip, audio_rate)\n",
    "                audio_B3_image = np.reshape(image, (512,299,1))\n",
    "                input_B.append(audio_B3_image)\n",
    "                break\n",
    "    \n",
    "    \n",
    "    \n",
    "    label = 0\n",
    "    labels.append(label)   \n",
    "    while True:\n",
    "        audio_A2 = random.choice(current_speaker_audios)\n",
    "        audio_data, _ = librosa.load(sr=None, mono=True, path=audio_A2)\n",
    "        if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                    start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                    end = start + (audio_rate*no_seconds)\n",
    "                    audio_clip = audio_data[start : end]\n",
    "                    image = audio_to_image(audio_clip, audio_rate)\n",
    "                    audio_A2_image = np.reshape(image, (512,299,1))\n",
    "                    input_A.append(audio_A2_image)\n",
    "                    break\n",
    "    while True:\n",
    "        audio_B4 = random.choice(current_speaker_audios)\n",
    "        audio_data, _ = librosa.load(sr=None, mono=True, path=audio_B4)\n",
    "        if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                    start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                    end = start + (audio_rate*no_seconds)\n",
    "                    audio_clip = audio_data[start : end]\n",
    "                    image = audio_to_image(audio_clip, audio_rate)\n",
    "                    audio_B4_image = np.reshape(image, (512,299,1))\n",
    "                    input_B.append(audio_B4_image)\n",
    "                    break\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        random_speaker = random.choice(speakers)\n",
    "        if random_speaker != current_speaker:         #The loop will run again if random.choice() resulted in the same speaker. Different is required.\n",
    "            break   \n",
    "    random_speaker_audios = glob(random_speaker + '/*.wav')\n",
    "    label = 1\n",
    "    labels.append(label)\n",
    "    audio_B5 = random.choice(random_speaker_audios)\n",
    "    audio_data, _ = librosa.load(sr=None, mono=True, path=audio_B5)\n",
    "    if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                end = start + (audio_rate*no_seconds)\n",
    "                audio_clip = audio_data[start : end]\n",
    "                image = audio_to_image(audio_clip, audio_rate)\n",
    "                audio_B5_image = np.reshape(image, (512,299,1))\n",
    "                input_B.append(audio_B5_image)\n",
    "                break\n",
    "    \n",
    "    \n",
    "    \n",
    "    while True:\n",
    "        random_speaker = random.choice(speakers)\n",
    "        if random_speaker != current_speaker:         #The loop will run again if random.choice() resulted in the same speaker. Different is required.\n",
    "            break   \n",
    "    random_speaker_audios = glob(random_speaker + '/*.wav')\n",
    "    label = 1\n",
    "    labels.append(label)\n",
    "    audio_B6 = random.choice(random_speaker_audios)\n",
    "    audio_data, _ = librosa.load(sr=None, mono=True, path=audio_B6)\n",
    "    if len(audio_data)/audio_rate >= no_seconds: #If 3+ sec audio is not found, loop will run again, else it will break.\n",
    "                start = random.randint(0, len(audio_data) - (audio_rate*no_seconds) )\n",
    "                end = start + (audio_rate*no_seconds)\n",
    "                audio_clip = audio_data[start : end]\n",
    "                image = audio_to_image(audio_clip, audio_rate)\n",
    "                audio_B6_image = np.reshape(image, (512,299,1))\n",
    "                input_B.append(audio_B6_image)\n",
    "                break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bob3",
   "language": "python",
   "name": "bob3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
